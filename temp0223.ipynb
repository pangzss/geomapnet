{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit514c6a0fe7ed4b2eb44685172323975d",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join('data', args.dataset)\n",
    "img_dirs = os.listdir(path) \n",
    "seed = args.seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "num_imgs = 9\n",
    "n_plts = int(np.sqrt(num_imgs))\n",
    "\n",
    "img_indices = np.random.randint(len(img_dirs),size = num_imgs)\n",
    "imgs_resized = [] # containing loaded images\n",
    "imgs_torch = [] # containing torch variables of images\n",
    "\n",
    "for index in img_indices:\n",
    "    img_name = osp.join(path,img_dirs[index])\n",
    "    img = load_image(img_name)\n",
    "    img_resized, img_torch = preprocess(img)\n",
    "    imgs_resized.append(img_resized)\n",
    "    imgs_torch.append(img_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = Image.open(filename).convert('RGB')\n",
    "    return img\n",
    "def preprocess(img):\n",
    "\n",
    "    img = np.asarray(img.resize((224, 224))) # resize to 224 * 224 (W * H), np.asarray returns (H, W, C)\n",
    "    img = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])(img)\n",
    "   \n",
    "    img = img[None,:,:,:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "dataset = 'AachenDay'\n",
    "path = osp.join('data', dataset)\n",
    "img_dirs = os.listdir(path) \n",
    "img_tensor = torch.zeros(len(img_dirs),3,224,224)\n",
    "for i,name in enumerate(img_dirs):\n",
    "    img_path = osp.join(path,name)\n",
    "    img = load_image(img_path)\n",
    "    img = preprocess(img)\n",
    "    img_tensor[i] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.rand(2,512,2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mat = mat.data.numpy()\n",
    "strong_activations = np.max(mat,axis=(2,3))\n",
    "strong_filters = np.argmax(strong_activations,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([377,  36])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual.filter_extractor import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./visual/AachenDay_files/img_dirs.txt', 'rb') as img_dirs:\n",
    "                pickle.load(img_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<_io.BufferedReader name='./visual/AachenDay_files/img_dirs.txt'>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[-0.44035208  0.14860178  2.04208146 -0.96398775  0.90118158]\n [-0.57906501  1.83107761  0.55693594  0.38088873 -1.58104453]\n [ 1.89423673 -0.23792438 -0.2953696  -0.34367811 -0.22116111]\n [ 0.92299091 -1.82094865 -1.91619678 -0.50655166  0.21724165]\n [ 0.61337021 -0.95293152 -0.42880754  0.90210753 -1.12523382]]\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "mat = np.random.randn(5,5)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 2)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argmax(mat),(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_slice(img, max_index,kernel_size=15):\n",
    "\n",
    "    \n",
    "    H,W = img.shape\n",
    "    h,w = max_index\n",
    "\n",
    "    radius = (kernel_size - 1)/2\n",
    "\n",
    "    left = w - radius\n",
    "    right = w + radius + 1\n",
    "    w_slice = slice( int(left*(left>=0) - (right-W+1)*(right>=W), \n",
    "                     int(right - (right-W+1)*(right>=W)) - left*(left<0)))\n",
    "\n",
    "    up = h - radius\n",
    "\n",
    "    down = h + radius + 1\n",
    "\n",
    "    h_slice = slice(int(up*(up>=0) -(down-H+1)*(down>=H)), \n",
    "                    int(down - (down-H+1)*(down>=H) - up*(up<0)))\n",
    "\n",
    "    return (h_slice, w_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e7edf35a58aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_patch_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-205c8e603772>\u001b[0m in \u001b[0;36mget_patch_slice\u001b[0;34m(img, max_index, kernel_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     w_slice = slice( int(left*(left>=0) - (right-W+1)*(right>=W), \n\u001b[0;32m---> 12\u001b[0;31m                      int(right - (right-W+1)*(right>=W)) - left*(left<0)))\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "mat = np.random.randn(224,224)\n",
    "get_patch_slice(mat, (0,1),kernel_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}