{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitmapnetreleaseconda4caa872d19b34b8590111941c54da5e6",
   "display_name": "Python 3.7.6 64-bit ('mapnet_release': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.train import load_state_dict\n",
    "loc_func = lambda storage, loc: storage\n",
    "weights_dir = '../scripts/logs/stylized_models/AachenDayNight__mapnet_stylized_4_styles_seed0.pth.tar'\n",
    "checkpoint= torch.load(weights_dir,map_location=loc_func)\n",
    "load_state_dict(mapnet_model,checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ".daa = {0:30, 2:28, 5:25, 7:23, 10:20, 12:18, 14:16, 17:13, 19:11, 21:9, 24:6, 26:4, 28:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 30,\n 2: 28,\n 5: 25,\n 7: 23,\n 10: 20,\n 12: 18,\n 14: 16,\n 17: 13,\n 19: 11,\n 21: 9,\n 24: 6,\n 26: 4,\n 28: 2}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,1,1],dtype=float)\n",
    "a.requires_grad = True\n",
    "b = a * 3\n",
    "c = b**2\n",
    "d = c * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "None\n"
    }
   ],
   "source": [
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The grad fn for a is None\nThe grad fn for d is <AddBackward0 object at 0x7f30a7b5da50>\n"
    }
   ],
   "source": [
    "a = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad = True)\n",
    "w2 = torch.randn((3,3), requires_grad = True)\n",
    "w3 = torch.randn((3,3), requires_grad = True)\n",
    "w4 = torch.randn((3,3), requires_grad = True)  # all the above are leaf nodes (weights)\n",
    "\n",
    "b = w1*a \n",
    "c = w2*a\n",
    "\n",
    "d = w3*b + w4*c \n",
    "\n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is\", a.grad_fn)\n",
    "print(\"The grad fn for d is\", d.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'data/x'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')\n",
    "os.path.join('data','x') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "conv = nn.Conv2d(1,1,3,padding=1,stride=1)\n",
    "deconv = nn.ConvTranspose2d(1, 1, 3, padding=1, output_padding=0,stride=1)\n",
    "# img even, op =1, img odd, op=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv  torch.Size([1, 1, 255, 255])\ndeconv torch.Size([1, 1, 255, 255])\n"
    }
   ],
   "source": [
    "\n",
    "img = torch.ones((1,1,255,255))\n",
    "\n",
    "img_conv = conv(img)\n",
    "print('conv ',img_conv.shape)\n",
    "img_deconv = deconv(img_conv)\n",
    "print('deconv', img_deconv.shape)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained = models.vgg16(pretrained = True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (18): ReLU(inplace=True)\n  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (25): ReLU(inplace=True)\n  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (27): ReLU(inplace=True)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "source": [
    "vgg16_pretrained.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nconv1\nbn1\nrelu\nmaxpool\nlayer1\nlayer1.0\nlayer1.0.conv1\nlayer1.0.bn1\nlayer1.0.relu\nlayer1.0.conv2\nlayer1.0.bn2\nlayer1.1\nlayer1.1.conv1\nlayer1.1.bn1\nlayer1.1.relu\nlayer1.1.conv2\nlayer1.1.bn2\nlayer1.2\nlayer1.2.conv1\nlayer1.2.bn1\nlayer1.2.relu\nlayer1.2.conv2\nlayer1.2.bn2\nlayer2\nlayer2.0\nlayer2.0.conv1\nlayer2.0.bn1\nlayer2.0.relu\nlayer2.0.conv2\nlayer2.0.bn2\nlayer2.0.downsample\nlayer2.0.downsample.0\nlayer2.0.downsample.1\nlayer2.1\nlayer2.1.conv1\nlayer2.1.bn1\nlayer2.1.relu\nlayer2.1.conv2\nlayer2.1.bn2\nlayer2.2\nlayer2.2.conv1\nlayer2.2.bn1\nlayer2.2.relu\nlayer2.2.conv2\nlayer2.2.bn2\nlayer2.3\nlayer2.3.conv1\nlayer2.3.bn1\nlayer2.3.relu\nlayer2.3.conv2\nlayer2.3.bn2\nlayer3\nlayer3.0\nlayer3.0.conv1\nlayer3.0.bn1\nlayer3.0.relu\nlayer3.0.conv2\nlayer3.0.bn2\nlayer3.0.downsample\nlayer3.0.downsample.0\nlayer3.0.downsample.1\nlayer3.1\nlayer3.1.conv1\nlayer3.1.bn1\nlayer3.1.relu\nlayer3.1.conv2\nlayer3.1.bn2\nlayer3.2\nlayer3.2.conv1\nlayer3.2.bn1\nlayer3.2.relu\nlayer3.2.conv2\nlayer3.2.bn2\nlayer3.3\nlayer3.3.conv1\nlayer3.3.bn1\nlayer3.3.relu\nlayer3.3.conv2\nlayer3.3.bn2\nlayer3.4\nlayer3.4.conv1\nlayer3.4.bn1\nlayer3.4.relu\nlayer3.4.conv2\nlayer3.4.bn2\nlayer3.5\nlayer3.5.conv1\nlayer3.5.bn1\nlayer3.5.relu\nlayer3.5.conv2\nlayer3.5.bn2\nlayer4\nlayer4.0\nlayer4.0.conv1\nlayer4.0.bn1\nlayer4.0.relu\nlayer4.0.conv2\nlayer4.0.bn2\nlayer4.0.downsample\nlayer4.0.downsample.0\nlayer4.0.downsample.1\nlayer4.1\nlayer4.1.conv1\nlayer4.1.bn1\nlayer4.1.relu\nlayer4.1.conv2\nlayer4.1.bn2\nlayer4.2\nlayer4.2.conv1\nlayer4.2.bn1\nlayer4.2.relu\nlayer4.2.conv2\nlayer4.2.bn2\navgpool\nfc\n"
    }
   ],
   "source": [
    "for name, module in res.named_modules():\n",
    "    print(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (18): ReLU(inplace=True)\n  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (25): ReLU(inplace=True)\n  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (27): ReLU(inplace=True)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "source": [
    "vgg16_pretrained._modules.get('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deconv_resnet import deconv_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "deconv_resnet(\n  (features): Sequential(\n    (0): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU(inplace=True)\n    (12): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (14): ReLU(inplace=True)\n    (15): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (23): ReLU(inplace=True)\n    (24): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (26): ReLU(inplace=True)\n    (27): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (41): ReLU(inplace=True)\n    (42): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (43): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (44): ReLU(inplace=True)\n    (45): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (46): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (47): ReLU(inplace=True)\n    (48): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (49): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (50): ReLU(inplace=True)\n    (51): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (52): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (53): ReLU(inplace=True)\n    (54): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (55): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (56): ReLU(inplace=True)\n    (57): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (58): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (59): ReLU(inplace=True)\n    (60): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (61): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (62): ReLU(inplace=True)\n    (63): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (64): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (65): ReLU(inplace=True)\n    (66): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (67): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (68): ReLU(inplace=True)\n    (69): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (70): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (71): ReLU(inplace=True)\n    (72): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (73): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (74): ReLU(inplace=True)\n    (75): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (76): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (77): ReLU(inplace=True)\n    (78): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (79): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (80): ReLU(inplace=True)\n    (81): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (82): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (83): ReLU(inplace=True)\n    (84): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (85): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (86): ReLU(inplace=True)\n    (87): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (88): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (89): ReLU(inplace=True)\n    (90): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (91): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (92): ReLU(inplace=True)\n    (93): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (94): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (95): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n    (96): ReLU(inplace=True)\n    (97): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (98): ConvTranspose2d(64, 3, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1))\n  )\n)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model = deconv_resnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.ones((1,3,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 1, 255, 255])\ntorch.Size([1, 1, 255, 255])\n"
    }
   ],
   "source": [
    "downsample = nn.Conv2d(1,1,1,stride=2)\n",
    "img = torch.ones((1,1,255,255))\n",
    "print(img.shape)\n",
    "out = downsample(img)\n",
    "if img.shape[2] %2 != 0: # img odd. 255->128, 128->255                               # no output padding\n",
    "    output_padding = 0\n",
    "else:                    # img even. 256->128, 128*>256\n",
    "                         # outpu padding = 1        \n",
    "    output_padding = 1\n",
    "upsample = nn.ConvTranspose2d(1,1,1,stride=2,output_padding=output_padding)\n",
    "out = upsample(out)\n",
    "print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 1, 128, 128])\n"
    }
   ],
   "source": [
    "downsample = nn.Conv2d(1,1,1,stride=2)\n",
    "img = torch.ones((1,1,255,255))\n",
    "out = downsample(img)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "odict_items([('layer1', Sequential(\n  (0): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (1): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (downsample): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (2): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)), ('layer2', Sequential(\n  (0): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (1): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (2): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (downsample): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (3): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)), ('layer3', Sequential(\n  (0): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (1): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (2): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (3): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (4): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)), ('layer4', Sequential(\n  (0): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (1): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (2): Block(\n    (relu1): ReLU(inplace=True)\n    (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu2): ReLU(inplace=True)\n    (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)), ('unpool', MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))), ('relu', ReLU(inplace=True)), ('conv_last', ConvTranspose2d(64, 3, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1), output_padding=(1, 1)))])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "model._modules.items()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Decon_ResNet(\n  (layer1): Sequential(\n    (0): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): Block(\n      (relu1): ReLU(inplace=True)\n      (deconv1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu2): ReLU(inplace=True)\n      (deconv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (relu): ReLU(inplace=True)\n  (conv_last): ConvTranspose2d(64, 3, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n)\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-731b22090b48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecon_ResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from backup import Decon_ResNet\n",
    "model = Decon_ResNet()\n",
    "\n",
    "img = torch.ones((1,3,256,256))\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Block(\n  (relu1): ReLU(inplace=True)\n  (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu2): ReLU(inplace=True)\n  (deconv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "layers[\"layer1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "res = models.resnet34(pretrained=True)\n",
    "layers = res._modules\n",
    "activations = {}\n",
    "\n",
    "#for layer in layers:\n",
    "#    if 'layer' in layer :\n",
    "#        activations[layer] = {}\n",
    "#        for i,block in enumerate(layers[layer]):\n",
    "            #activations[layer]['block'+str(i)] = output\n",
    "def get_activation(layer,blk_index):\n",
    "    def hook(module,input,output):\n",
    "        #activations[layer]['block'+str(blk_index)]= output.detach()\n",
    "        if 'maxpool' in layer:\n",
    "            activations[layer]['actvation']= output[0]\n",
    "            activations[layer]['pool_indices']= output[1]\n",
    "        else:\n",
    "            activations[layer]['block'+str(blk_index)]= output\n",
    "    return hook\n",
    "\n",
    "blk_hooks = {}\n",
    "for layer in layers:\n",
    "    if 'layer' in layer :\n",
    "        activations[layer] = {}\n",
    "        blk_hooks[layer] = {}\n",
    "        for blk_index,block in enumerate(layers[layer]):\n",
    "            blk_hooks[layer]['block'+str(blk_index)] = block.register_forward_hook(get_activation(layer,blk_index))\n",
    "    elif 'maxpool' in layer:\n",
    "        activations[layer] = {}\n",
    "        blk_hooks[layer] = {}\n",
    "        blk_hooks[layer] = block.register_forward_hook(get_activation(layer,0))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "img = torch.ones((1,3,256,256))\n",
    "out = res(img)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "a = {'1':1,'2':2,'3':3}\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import set_paths\n",
    "from models.posenet import PoseNet, MapNet\n",
    "from torchvision import models \n",
    "import configparser\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "with open('../scripts/configs/style.ini','r') as f:\n",
    "    settings.read_file(f)\n",
    "section = settings['hyperparameters']\n",
    "dropout = section.getfloat('dropout')\n",
    "feature_extractor = models.resnet34(pretrained=False)\n",
    "posenet = PoseNet(feature_extractor, droprate=dropout, pretrained=False)\n",
    "\n",
    "mapnet_model = MapNet(mapnet=posenet)\n",
    "# load weights\n",
    "dir_weights = '../scripts/logs/stylized_models/AachenDayNight__mapnet_stylized_4_styles_seed0.pth.tar'\n",
    "loaded_model= torch.load(dir_weights)\n",
    "# transfer the weights of mapne_model to conv_model\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MapNet:\n\tMissing key(s) in state_dict: \"mapnet.feature_extractor.conv1.weight\", \"mapnet.feature_extractor.bn1.weight\", \"mapnet.feature_extractor.bn1.bias\", \"mapnet.feature_extractor.bn1.running_mean\", \"mapnet.feature_extractor.bn1.running_var\", \"mapnet.feature_extractor.layer1.0.conv1.weight\", \"mapnet.feature_extractor.layer1.0.bn1.weight\", \"mapnet.feature_extractor.layer1.0.bn1.bias\", \"mapnet.feature_extractor.layer1.0.bn1.running_mean\", \"mapnet.feature_extractor.layer1.0.bn1.running_var\", \"mapnet.feature_extractor.layer1.0.conv2.weight\", \"mapnet.feature_extractor.layer1.0.bn2.weight\", \"mapnet.feature_extractor.layer1.0.bn2.bias\", \"mapnet.feature_extractor.layer1.0.bn2.running_mean\", \"mapnet.feature_extractor.layer1.0.bn2.running_var\", \"mapnet.feature_extractor.layer1.1.conv1.weight\", \"mapnet.feature_extractor.layer1.1.bn1.weight\", \"mapnet.feature_extractor.layer1.1.bn1.bias\", \"mapnet.feature_extractor.layer1.1.bn1.running_mean\", \"mapnet.feature_extractor.layer1.1.bn1.running_var\", \"mapnet.feature_extractor.layer1.1.conv2.weight\", \"mapnet.feature_extractor.layer1.1.bn2.weight\", \"mapnet.feature_extractor.layer1.1.bn2.bias\", \"mapnet.feature_extractor.layer1.1.bn2.running_mean\", \"mapnet.feature_extractor.layer1.1.bn2.running_var\", \"mapnet.feature_extractor.layer1.2.conv1.weight\", \"mapnet.feature_extractor.layer1.2.bn1.weight\", \"mapnet.feature_extractor.layer1.2.bn1.bias\", \"mapnet.feature_extractor.layer1.2.bn1.running_mean\", \"mapnet.feature_extractor.layer1.2.bn1.running_var\", \"mapnet.feature_extractor.layer1.2.conv2.weight\", \"mapnet.feature_extractor.layer1.2.bn2.weight\", \"mapnet.feature_extractor.layer1.2.bn2.bias\", \"mapnet.feature_extractor.layer1.2.bn2.running_mean\", \"mapnet.feature_extractor.layer1.2.bn2.running_var\", \"mapnet.feature_extractor.layer2.0.conv1.weight\", \"mapnet.feature_extractor.layer2.0.bn1.weight\", \"mapnet.feature_extractor.layer2.0.bn1.bias\", \"mapnet.feature_extractor.layer2.0.bn1.running_mean\", \"mapnet.feature_extractor.layer2.0.bn1.running_var\", \"mapnet.feature_extractor.layer2.0.conv2.weight\", \"mapnet.feature_extractor.layer2.0.bn2.weight\", \"mapnet.feature_extractor.layer2.0.bn2.bias\", \"mapnet.feature_extractor.layer2.0.bn2.running_mean\", \"mapnet.feature_extractor.layer2.0.bn2.running_var\", \"mapnet.feature_extractor.layer2.0.downsample.0.weight\", \"mapnet.feature_extractor.layer2.0.downsample.1.weight\", \"mapnet.feature_extractor.layer2.0.downsample.1.bias\", \"mapnet.feature_extractor.layer2.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer2.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer2.1.conv1.weight\", \"mapnet.feature_extractor.layer2.1.bn1.weight\", \"mapnet.feature_extractor.layer2.1.bn1.bias\", \"mapnet.feature_extractor.layer2.1.bn1.running_mean\", \"mapnet.feature_extractor.layer2.1.bn1.running_var\", \"mapnet.feature_extractor.layer2.1.conv2.weight\", \"mapnet.feature_extractor.layer2.1.bn2.weight\", \"mapnet.feature_extractor.layer2.1.bn2.bias\", \"mapnet.feature_extractor.layer2.1.bn2.running_mean\", \"mapnet.feature_extractor.layer2.1.bn2.running_var\", \"mapnet.feature_extractor.layer2.2.conv1.weight\", \"mapnet.feature_extractor.layer2.2.bn1.weight\", \"mapnet.feature_extractor.layer2.2.bn1.bias\", \"mapnet.feature_extractor.layer2.2.bn1.running_mean\", \"mapnet.feature_extractor.layer2.2.bn1.running_var\", \"mapnet.feature_extractor.layer2.2.conv2.weight\", \"mapnet.feature_extractor.layer2.2.bn2.weight\", \"mapnet.feature_extractor.layer2.2.bn2.bias\", \"mapnet.feature_extractor.layer2.2.bn2.running_mean\", \"mapnet.feature_extractor.layer2.2.bn2.running_var\", \"mapnet.feature_extractor.layer2.3.conv1.weight\", \"mapnet.feature_extractor.layer2.3.bn1.weight\", \"mapnet.feature_extractor.layer2.3.bn1.bias\", \"mapnet.feature_extractor.layer2.3.bn1.running_mean\", \"mapnet.feature_extractor.layer2.3.bn1.running_var\", \"mapnet.feature_extractor.layer2.3.conv2.weight\", \"mapnet.feature_extractor.layer2.3.bn2.weight\", \"mapnet.feature_extractor.layer2.3.bn2.bias\", \"mapnet.feature_extractor.layer2.3.bn2.running_mean\", \"mapnet.feature_extractor.layer2.3.bn2.running_var\", \"mapnet.feature_extractor.layer3.0.conv1.weight\", \"mapnet.feature_extractor.layer3.0.bn1.weight\", \"mapnet.feature_extractor.layer3.0.bn1.bias\", \"mapnet.feature_extractor.layer3.0.bn1.running_mean\", \"mapnet.feature_extractor.layer3.0.bn1.running_var\", \"mapnet.feature_extractor.layer3.0.conv2.weight\", \"mapnet.feature_extractor.layer3.0.bn2.weight\", \"mapnet.feature_extractor.layer3.0.bn2.bias\", \"mapnet.feature_extractor.layer3.0.bn2.running_mean\", \"mapnet.feature_extractor.layer3.0.bn2.running_var\", \"mapnet.feature_extractor.layer3.0.downsample.0.weight\", \"mapnet.feature_extractor.layer3.0.downsample.1.weight\", \"mapnet.feature_extractor.layer3.0.downsample.1.bias\", \"mapnet.feature_extractor.layer3.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer3.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer3.1.conv1.weight\", \"mapnet.feature_extractor.layer3.1.bn1.weight\", \"mapnet.feature_extractor.layer3.1.bn1.bias\", \"mapnet.feature_extractor.layer3.1.bn1.running_mean\", \"mapnet.feature_extractor.layer3.1.bn1.running_var\", \"mapnet.feature_extractor.layer3.1.conv2.weight\", \"mapnet.feature_extractor.layer3.1.bn2.weight\", \"mapnet.feature_extractor.layer3.1.bn2.bias\", \"mapnet.feature_extractor.layer3.1.bn2.running_mean\", \"mapnet.feature_extractor.layer3.1.bn2.running_var\", \"mapnet.feature_extractor.layer3.2.conv1.weight\", \"mapnet.feature_extractor.layer3.2.bn1.weight\", \"mapnet.feature_extractor.layer3.2.bn1.bias\", \"mapnet.feature_extractor.layer3.2.bn1.running_mean\", \"mapnet.feature_extractor.layer3.2.bn1.running_var\", \"mapnet.feature_extractor.layer3.2.conv2.weight\", \"mapnet.feature_extractor.layer3.2.bn2.weight\", \"mapnet.feature_extractor.layer3.2.bn2.bias\", \"mapnet.feature_extractor.layer3.2.bn2.running_mean\", \"mapnet.feature_extractor.layer3.2.bn2.running_var\", \"mapnet.feature_extractor.layer3.3.conv1.weight\", \"mapnet.feature_extractor.layer3.3.bn1.weight\", \"mapnet.feature_extractor.layer3.3.bn1.bias\", \"mapnet.feature_extractor.layer3.3.bn1.running_mean\", \"mapnet.feature_extractor.layer3.3.bn1.running_var\", \"mapnet.feature_extractor.layer3.3.conv2.weight\", \"mapnet.feature_extractor.layer3.3.bn2.weight\", \"mapnet.feature_extractor.layer3.3.bn2.bias\", \"mapnet.feature_extractor.layer3.3.bn2.running_mean\", \"mapnet.feature_extractor.layer3.3.bn2.running_var\", \"mapnet.feature_extractor.layer3.4.conv1.weight\", \"mapnet.feature_extractor.layer3.4.bn1.weight\", \"mapnet.feature_extractor.layer3.4.bn1.bias\", \"mapnet.feature_extractor.layer3.4.bn1.running_mean\", \"mapnet.feature_extractor.layer3.4.bn1.running_var\", \"mapnet.feature_extractor.layer3.4.conv2.weight\", \"mapnet.feature_extractor.layer3.4.bn2.weight\", \"mapnet.feature_extractor.layer3.4.bn2.bias\", \"mapnet.feature_extractor.layer3.4.bn2.running_mean\", \"mapnet.feature_extractor.layer3.4.bn2.running_var\", \"mapnet.feature_extractor.layer3.5.conv1.weight\", \"mapnet.feature_extractor.layer3.5.bn1.weight\", \"mapnet.feature_extractor.layer3.5.bn1.bias\", \"mapnet.feature_extractor.layer3.5.bn1.running_mean\", \"mapnet.feature_extractor.layer3.5.bn1.running_var\", \"mapnet.feature_extractor.layer3.5.conv2.weight\", \"mapnet.feature_extractor.layer3.5.bn2.weight\", \"mapnet.feature_extractor.layer3.5.bn2.bias\", \"mapnet.feature_extractor.layer3.5.bn2.running_mean\", \"mapnet.feature_extractor.layer3.5.bn2.running_var\", \"mapnet.feature_extractor.layer4.0.conv1.weight\", \"mapnet.feature_extractor.layer4.0.bn1.weight\", \"mapnet.feature_extractor.layer4.0.bn1.bias\", \"mapnet.feature_extractor.layer4.0.bn1.running_mean\", \"mapnet.feature_extractor.layer4.0.bn1.running_var\", \"mapnet.feature_extractor.layer4.0.conv2.weight\", \"mapnet.feature_extractor.layer4.0.bn2.weight\", \"mapnet.feature_extractor.layer4.0.bn2.bias\", \"mapnet.feature_extractor.layer4.0.bn2.running_mean\", \"mapnet.feature_extractor.layer4.0.bn2.running_var\", \"mapnet.feature_extractor.layer4.0.downsample.0.weight\", \"mapnet.feature_extractor.layer4.0.downsample.1.weight\", \"mapnet.feature_extractor.layer4.0.downsample.1.bias\", \"mapnet.feature_extractor.layer4.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer4.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer4.1.conv1.weight\", \"mapnet.feature_extractor.layer4.1.bn1.weight\", \"mapnet.feature_extractor.layer4.1.bn1.bias\", \"mapnet.feature_extractor.layer4.1.bn1.running_mean\", \"mapnet.feature_extractor.layer4.1.bn1.running_var\", \"mapnet.feature_extractor.layer4.1.conv2.weight\", \"mapnet.feature_extractor.layer4.1.bn2.weight\", \"mapnet.feature_extractor.layer4.1.bn2.bias\", \"mapnet.feature_extractor.layer4.1.bn2.running_mean\", \"mapnet.feature_extractor.layer4.1.bn2.running_var\", \"mapnet.feature_extractor.layer4.2.conv1.weight\", \"mapnet.feature_extractor.layer4.2.bn1.weight\", \"mapnet.feature_extractor.layer4.2.bn1.bias\", \"mapnet.feature_extractor.layer4.2.bn1.running_mean\", \"mapnet.feature_extractor.layer4.2.bn1.running_var\", \"mapnet.feature_extractor.layer4.2.conv2.weight\", \"mapnet.feature_extractor.layer4.2.bn2.weight\", \"mapnet.feature_extractor.layer4.2.bn2.bias\", \"mapnet.feature_extractor.layer4.2.bn2.running_mean\", \"mapnet.feature_extractor.layer4.2.bn2.running_var\", \"mapnet.feature_extractor.fc.weight\", \"mapnet.feature_extractor.fc.bias\", \"mapnet.fc_xyz.weight\", \"mapnet.fc_xyz.bias\", \"mapnet.fc_wpqr.weight\", \"mapnet.fc_wpqr.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"criterion_state_dict\", \"epoch\", \"optim_state_dict\". ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-01136a00b8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmapnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mapnet_release/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MapNet:\n\tMissing key(s) in state_dict: \"mapnet.feature_extractor.conv1.weight\", \"mapnet.feature_extractor.bn1.weight\", \"mapnet.feature_extractor.bn1.bias\", \"mapnet.feature_extractor.bn1.running_mean\", \"mapnet.feature_extractor.bn1.running_var\", \"mapnet.feature_extractor.layer1.0.conv1.weight\", \"mapnet.feature_extractor.layer1.0.bn1.weight\", \"mapnet.feature_extractor.layer1.0.bn1.bias\", \"mapnet.feature_extractor.layer1.0.bn1.running_mean\", \"mapnet.feature_extractor.layer1.0.bn1.running_var\", \"mapnet.feature_extractor.layer1.0.conv2.weight\", \"mapnet.feature_extractor.layer1.0.bn2.weight\", \"mapnet.feature_extractor.layer1.0.bn2.bias\", \"mapnet.feature_extractor.layer1.0.bn2.running_mean\", \"mapnet.feature_extractor.layer1.0.bn2.running_var\", \"mapnet.feature_extractor.layer1.1.conv1.weight\", \"mapnet.feature_extractor.layer1.1.bn1.weight\", \"mapnet.feature_extractor.layer1.1.bn1.bias\", \"mapnet.feature_extractor.layer1.1.bn1.running_mean\", \"mapnet.feature_extractor.layer1.1.bn1.running_var\", \"mapnet.feature_extractor.layer1.1.conv2.weight\", \"mapnet.feature_extractor.layer1.1.bn2.weight\", \"mapnet.feature_extractor.layer1.1.bn2.bias\", \"mapnet.feature_extractor.layer1.1.bn2.running_mean\", \"mapnet.feature_extractor.layer1.1.bn2.running_var\", \"mapnet.feature_extractor.layer1.2.conv1.weight\", \"mapnet.feature_extractor.layer1.2.bn1.weight\", \"mapnet.feature_extractor.layer1.2.bn1.bias\", \"mapnet.feature_extractor.layer1.2.bn1.running_mean\", \"mapnet.feature_extractor.layer1.2.bn1.running_var\", \"mapnet.feature_extractor.layer1.2.conv2.weight\", \"mapnet.feature_extractor.layer1.2.bn2.weight\", \"mapnet.feature_extractor.layer1.2.bn2.bias\", \"mapnet.feature_extractor.layer1.2.bn2.running_mean\", \"mapnet.feature_extractor.layer1.2.bn2.running_var\", \"mapnet.feature_extractor.layer2.0.conv1.weight\", \"mapnet.feature_extractor.layer2.0.bn1.weight\", \"mapnet.feature_extractor.layer2.0.bn1.bias\", \"mapnet.feature_extractor.layer2.0.bn1.running_mean\", \"mapnet.feature_extractor.layer2.0.bn1.running_var\", \"mapnet.feature_extractor.layer2.0.conv2.weight\", \"mapnet.feature_extractor.layer2.0.bn2.weight\", \"mapnet.feature_extractor.layer2.0.bn2.bias\", \"mapnet.feature_extractor.layer2.0.bn2.running_mean\", \"mapnet.feature_extractor.layer2.0.bn2.running_var\", \"mapnet.feature_extractor.layer2.0.downsample.0.weight\", \"mapnet.feature_extractor.layer2.0.downsample.1.weight\", \"mapnet.feature_extractor.layer2.0.downsample.1.bias\", \"mapnet.feature_extractor.layer2.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer2.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer2.1.conv1.weight\", \"mapnet.feature_extractor.layer2.1.bn1.weight\", \"mapnet.feature_extractor.layer2.1.bn1.bias\", \"mapnet.feature_extractor.layer2.1.bn1.running_mean\", \"mapnet.feature_extractor.layer2.1.bn1.running_var\", \"mapnet.feature_extractor.layer2.1.conv2.weight\", \"mapnet.feature_extractor.layer2.1.bn2.weight\", \"mapnet.feature_extractor.layer2.1.bn2.bias\", \"mapnet.feature_extractor.layer2.1.bn2.running_mean\", \"mapnet.feature_extractor.layer2.1.bn2.running_var\", \"mapnet.feature_extractor.layer2.2.conv1.weight\", \"mapnet.feature_extractor.layer2.2.bn1.weight\", \"mapnet.feature_extractor.layer2.2.bn1.bias\", \"mapnet.feature_extractor.layer2.2.bn1.running_mean\", \"mapnet.feature_extractor.layer2.2.bn1.running_var\", \"mapnet.feature_extractor.layer2.2.conv2.weight\", \"mapnet.feature_extractor.layer2.2.bn2.weight\", \"mapnet.feature_extractor.layer2.2.bn2.bias\", \"mapnet.feature_extractor.layer2.2.bn2.running_mean\", \"mapnet.feature_extractor.layer2.2.bn2.running_var\", \"mapnet.feature_extractor.layer2.3.conv1.weight\", \"mapnet.feature_extractor.layer2.3.bn1.weight\", \"mapnet.feature_extractor.layer2.3.bn1.bias\", \"mapnet.feature_extractor.layer2.3.bn1.running_mean\", \"mapnet.feature_extractor.layer2.3.bn1.running_var\", \"mapnet.feature_extractor.layer2.3.conv2.weight\", \"mapnet.feature_extractor.layer2.3.bn2.weight\", \"mapnet.feature_extractor.layer2.3.bn2.bias\", \"mapnet.feature_extractor.layer2.3.bn2.running_mean\", \"mapnet.feature_extractor.layer2.3.bn2.running_var\", \"mapnet.feature_extractor.layer3.0.conv1.weight\", \"mapnet.feature_extractor.layer3.0.bn1.weight\", \"mapnet.feature_extractor.layer3.0.bn1.bias\", \"mapnet.feature_extractor.layer3.0.bn1.running_mean\", \"mapnet.feature_extractor.layer3.0.bn1.running_var\", \"mapnet.feature_extractor.layer3.0.conv2.weight\", \"mapnet.feature_extractor.layer3.0.bn2.weight\", \"mapnet.feature_extractor.layer3.0.bn2.bias\", \"mapnet.feature_extractor.layer3.0.bn2.running_mean\", \"mapnet.feature_extractor.layer3.0.bn2.running_var\", \"mapnet.feature_extractor.layer3.0.downsample.0.weight\", \"mapnet.feature_extractor.layer3.0.downsample.1.weight\", \"mapnet.feature_extractor.layer3.0.downsample.1.bias\", \"mapnet.feature_extractor.layer3.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer3.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer3.1.conv1.weight\", \"mapnet.feature_extractor.layer3.1.bn1.weight\", \"mapnet.feature_extractor.layer3.1.bn1.bias\", \"mapnet.feature_extractor.layer3.1.bn1.running_mean\", \"mapnet.feature_extractor.layer3.1.bn1.running_var\", \"mapnet.feature_extractor.layer3.1.conv2.weight\", \"mapnet.feature_extractor.layer3.1.bn2.weight\", \"mapnet.feature_extractor.layer3.1.bn2.bias\", \"mapnet.feature_extractor.layer3.1.bn2.running_mean\", \"mapnet.feature_extractor.layer3.1.bn2.running_var\", \"mapnet.feature_extractor.layer3.2.conv1.weight\", \"mapnet.feature_extractor.layer3.2.bn1.weight\", \"mapnet.feature_extractor.layer3.2.bn1.bias\", \"mapnet.feature_extractor.layer3.2.bn1.running_mean\", \"mapnet.feature_extractor.layer3.2.bn1.running_var\", \"mapnet.feature_extractor.layer3.2.conv2.weight\", \"mapnet.feature_extractor.layer3.2.bn2.weight\", \"mapnet.feature_extractor.layer3.2.bn2.bias\", \"mapnet.feature_extractor.layer3.2.bn2.running_mean\", \"mapnet.feature_extractor.layer3.2.bn2.running_var\", \"mapnet.feature_extractor.layer3.3.conv1.weight\", \"mapnet.feature_extractor.layer3.3.bn1.weight\", \"mapnet.feature_extractor.layer3.3.bn1.bias\", \"mapnet.feature_extractor.layer3.3.bn1.running_mean\", \"mapnet.feature_extractor.layer3.3.bn1.running_var\", \"mapnet.feature_extractor.layer3.3.conv2.weight\", \"mapnet.feature_extractor.layer3.3.bn2.weight\", \"mapnet.feature_extractor.layer3.3.bn2.bias\", \"mapnet.feature_extractor.layer3.3.bn2.running_mean\", \"mapnet.feature_extractor.layer3.3.bn2.running_var\", \"mapnet.feature_extractor.layer3.4.conv1.weight\", \"mapnet.feature_extractor.layer3.4.bn1.weight\", \"mapnet.feature_extractor.layer3.4.bn1.bias\", \"mapnet.feature_extractor.layer3.4.bn1.running_mean\", \"mapnet.feature_extractor.layer3.4.bn1.running_var\", \"mapnet.feature_extractor.layer3.4.conv2.weight\", \"mapnet.feature_extractor.layer3.4.bn2.weight\", \"mapnet.feature_extractor.layer3.4.bn2.bias\", \"mapnet.feature_extractor.layer3.4.bn2.running_mean\", \"mapnet.feature_extractor.layer3.4.bn2.running_var\", \"mapnet.feature_extractor.layer3.5.conv1.weight\", \"mapnet.feature_extractor.layer3.5.bn1.weight\", \"mapnet.feature_extractor.layer3.5.bn1.bias\", \"mapnet.feature_extractor.layer3.5.bn1.running_mean\", \"mapnet.feature_extractor.layer3.5.bn1.running_var\", \"mapnet.feature_extractor.layer3.5.conv2.weight\", \"mapnet.feature_extractor.layer3.5.bn2.weight\", \"mapnet.feature_extractor.layer3.5.bn2.bias\", \"mapnet.feature_extractor.layer3.5.bn2.running_mean\", \"mapnet.feature_extractor.layer3.5.bn2.running_var\", \"mapnet.feature_extractor.layer4.0.conv1.weight\", \"mapnet.feature_extractor.layer4.0.bn1.weight\", \"mapnet.feature_extractor.layer4.0.bn1.bias\", \"mapnet.feature_extractor.layer4.0.bn1.running_mean\", \"mapnet.feature_extractor.layer4.0.bn1.running_var\", \"mapnet.feature_extractor.layer4.0.conv2.weight\", \"mapnet.feature_extractor.layer4.0.bn2.weight\", \"mapnet.feature_extractor.layer4.0.bn2.bias\", \"mapnet.feature_extractor.layer4.0.bn2.running_mean\", \"mapnet.feature_extractor.layer4.0.bn2.running_var\", \"mapnet.feature_extractor.layer4.0.downsample.0.weight\", \"mapnet.feature_extractor.layer4.0.downsample.1.weight\", \"mapnet.feature_extractor.layer4.0.downsample.1.bias\", \"mapnet.feature_extractor.layer4.0.downsample.1.running_mean\", \"mapnet.feature_extractor.layer4.0.downsample.1.running_var\", \"mapnet.feature_extractor.layer4.1.conv1.weight\", \"mapnet.feature_extractor.layer4.1.bn1.weight\", \"mapnet.feature_extractor.layer4.1.bn1.bias\", \"mapnet.feature_extractor.layer4.1.bn1.running_mean\", \"mapnet.feature_extractor.layer4.1.bn1.running_var\", \"mapnet.feature_extractor.layer4.1.conv2.weight\", \"mapnet.feature_extractor.layer4.1.bn2.weight\", \"mapnet.feature_extractor.layer4.1.bn2.bias\", \"mapnet.feature_extractor.layer4.1.bn2.running_mean\", \"mapnet.feature_extractor.layer4.1.bn2.running_var\", \"mapnet.feature_extractor.layer4.2.conv1.weight\", \"mapnet.feature_extractor.layer4.2.bn1.weight\", \"mapnet.feature_extractor.layer4.2.bn1.bias\", \"mapnet.feature_extractor.layer4.2.bn1.running_mean\", \"mapnet.feature_extractor.layer4.2.bn1.running_var\", \"mapnet.feature_extractor.layer4.2.conv2.weight\", \"mapnet.feature_extractor.layer4.2.bn2.weight\", \"mapnet.feature_extractor.layer4.2.bn2.bias\", \"mapnet.feature_extractor.layer4.2.bn2.running_mean\", \"mapnet.feature_extractor.layer4.2.bn2.running_var\", \"mapnet.feature_extractor.fc.weight\", \"mapnet.feature_extractor.fc.bias\", \"mapnet.fc_xyz.weight\", \"mapnet.fc_xyz.bias\", \"mapnet.fc_wpqr.weight\", \"mapnet.fc_wpqr.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\", \"criterion_state_dict\", \"epoch\", \"optim_state_dict\". "
     ]
    }
   ],
   "source": [
    "mapnet_model.load_state_dict(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}